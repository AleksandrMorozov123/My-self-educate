{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/gpt-architecture?scriptVersionId=237378326\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"eec3e5bf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-05-02T10:40:48.434833Z","iopub.status.busy":"2025-05-02T10:40:48.434541Z","iopub.status.idle":"2025-05-02T10:40:49.934631Z","shell.execute_reply":"2025-05-02T10:40:49.933508Z"},"papermill":{"duration":1.504929,"end_time":"2025-05-02T10:40:49.936261","exception":false,"start_time":"2025-05-02T10:40:48.431332","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"8709583b","metadata":{"papermill":{"duration":0.001448,"end_time":"2025-05-02T10:40:49.939791","exception":false,"start_time":"2025-05-02T10:40:49.938343","status":"completed"},"tags":[]},"source":["**In this notebook I will create GPT (Generative Pretrained Transformer) small model and training this later**"]},{"cell_type":"code","execution_count":2,"id":"89864e62","metadata":{"execution":{"iopub.execute_input":"2025-05-02T10:40:49.944166Z","iopub.status.busy":"2025-05-02T10:40:49.94359Z","iopub.status.idle":"2025-05-02T10:40:49.962226Z","shell.execute_reply":"2025-05-02T10:40:49.961407Z"},"papermill":{"duration":0.022159,"end_time":"2025-05-02T10:40:49.963469","exception":false,"start_time":"2025-05-02T10:40:49.94131","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["matplolib version:  3.7.5\n","torch version:  2.5.1+cu124\n","tiktoken version:  0.9.0\n"]}],"source":["from importlib.metadata import version\n","\n","print(\"matplolib version: \", version(\"matplotlib\"))\n","print(\"torch version: \", version(\"torch\"))\n","print(\"tiktoken version: \", version(\"tiktoken\"))"]},{"cell_type":"code","execution_count":3,"id":"542b469e","metadata":{"execution":{"iopub.execute_input":"2025-05-02T10:40:49.967901Z","iopub.status.busy":"2025-05-02T10:40:49.967656Z","iopub.status.idle":"2025-05-02T10:40:49.971182Z","shell.execute_reply":"2025-05-02T10:40:49.970631Z"},"papermill":{"duration":0.006858,"end_time":"2025-05-02T10:40:49.972231","exception":false,"start_time":"2025-05-02T10:40:49.965373","status":"completed"},"tags":[]},"outputs":[],"source":["# configuration of the GPT model\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,     # vocabulary size\n","    \"context_length\": 1024,  # context length\n","    \"emb_dim\": 768,          # embedding dimensions\n","    \"n_heads\": 12,           # number of attention heads\n","    \"n_layers\": 12,          # number of layers\n","    \"drop_rate\": 0.1,        # dropout rate\n","    \"qkv_bias\": False        # Query-Key-Value bias\n","}"]},{"cell_type":"code","execution_count":4,"id":"49c26bf6","metadata":{"execution":{"iopub.execute_input":"2025-05-02T10:40:49.976641Z","iopub.status.busy":"2025-05-02T10:40:49.976022Z","iopub.status.idle":"2025-05-02T10:40:53.665259Z","shell.execute_reply":"2025-05-02T10:40:53.664468Z"},"papermill":{"duration":3.692765,"end_time":"2025-05-02T10:40:53.666673","exception":false,"start_time":"2025-05-02T10:40:49.973908","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class DummyGPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        # use a placeholder for Transformer Block\n","        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","        # use a placeholder for Layer Norm\n","        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits\n","\n","class DummyTransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x \n","\n","class DummyLayerNorm(nn.Module):\n","    def __init__(self, normalized_shape, eps=1e-5):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x"]},{"cell_type":"code","execution_count":5,"id":"a1fb9aa4","metadata":{"execution":{"iopub.execute_input":"2025-05-02T10:40:53.671171Z","iopub.status.busy":"2025-05-02T10:40:53.670848Z","iopub.status.idle":"2025-05-02T10:40:55.308845Z","shell.execute_reply":"2025-05-02T10:40:55.307989Z"},"papermill":{"duration":1.641591,"end_time":"2025-05-02T10:40:55.310169","exception":false,"start_time":"2025-05-02T10:40:53.668578","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1532,   345, 20078,   290,   220],\n","        [ 1639,  7765,   790,  1110,   290]])\n"]}],"source":["# encoding process\n","import tiktoken\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","batch = []\n","\n","txt1 = \"If you grind and \"\n","txt2 = \"You wake every day and\"\n","\n","batch.append(torch.tensor(tokenizer.encode(txt1)))\n","batch.append(torch.tensor(tokenizer.encode(txt2)))\n","batch = torch.stack(batch, dim=0)\n","print(batch)"]},{"cell_type":"code","execution_count":6,"id":"24ebe1fc","metadata":{"execution":{"iopub.execute_input":"2025-05-02T10:40:55.315099Z","iopub.status.busy":"2025-05-02T10:40:55.314547Z","iopub.status.idle":"2025-05-02T10:40:56.095128Z","shell.execute_reply":"2025-05-02T10:40:56.094349Z"},"papermill":{"duration":0.784257,"end_time":"2025-05-02T10:40:56.09642","exception":false,"start_time":"2025-05-02T10:40:55.312163","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([2, 5, 50257])\n","tensor([[[-0.4086,  1.0408, -0.5351,  ..., -1.6850, -0.2098,  0.3704],\n","         [-0.1377,  1.9332, -0.4629,  ..., -0.4409, -0.0980,  0.0817],\n","         [ 0.2650, -0.0898, -0.0479,  ...,  0.4372,  0.3871,  0.2004],\n","         [-0.5968,  0.7088,  1.3957,  ...,  0.4451,  1.5210,  0.8915],\n","         [-0.7740, -0.9768,  1.2553,  ...,  0.7457, -0.4746,  0.2609]],\n","\n","        [[-0.1776,  0.6227, -0.0074,  ..., -1.2598, -0.6497,  0.8217],\n","         [-0.6403,  1.4392, -1.2086,  ...,  0.9956,  1.0368,  2.2615],\n","         [-0.2581, -0.2354, -0.3046,  ..., -0.9638,  0.7429, -0.2973],\n","         [-0.0722,  0.5075,  0.0342,  ...,  1.2990,  0.3487,  0.2775],\n","         [-1.0624, -0.9751,  2.0261,  ..., -1.3601,  0.3677,  0.0639]]],\n","       grad_fn=<UnsafeViewBackward0>)\n"]}],"source":["torch.manual_seed(123)\n","model = DummyGPTModel(GPT_CONFIG_124M)\n","\n","logits = model(batch)\n","print(\"Output shape:\", logits.shape)\n","print(logits)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":14.227827,"end_time":"2025-05-02T10:40:58.585782","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-02T10:40:44.357955","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}